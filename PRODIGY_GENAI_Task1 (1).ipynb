{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXB1u4l2bN1C",
        "outputId": "ad655d1c-5e5f-4ded-f206-87df46268913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=80) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is Nilisha and I'm exploring the world of Generative AI. I'm a developer for a company called Genentech and a member of the team that created the game that will be released later this year. I've been writing about the game for the past few months and I'm hoping to continue this journey with this game.\n",
            "\n",
            "\n",
            "I'm looking forward to seeing you in the next month or so, I've been working on things like the campaign, the multiplayer, the new maps, some new weapons, and the general story.\n",
            "\n",
            "\n",
            "I'm also looking forward to seeing you on the Steam Workshop.\n",
            "\n",
            "\n",
            "Thank you so much for your time so far.\n",
            "\n",
            "\n",
            "- Nilisha Nilisha\n",
            "\n",
            "- Nilisha Nilisha\n",
            "\n",
            "- Nilisha Nilisha\n",
            "\n",
            "- Nilisha Nilisha\n",
            "\n",
            "- Nilisha Nilisha\n",
            "\n",
            "\n",
            "I've been working on Genentech since July 2015 and I've been working on Generative AI since August 2015. I've been working on the game for the past few months and I've been hoping to continue this journey with this game.I'm looking forward to seeing you in the next month or so, I've been working on things like the campaign, the multiplayer, the new maps, some new weapons, and the general story.I'm also looking forward to seeing you\n"
          ]
        }
      ],
      "source": [
        "# Install the Transformers library (only needed once)\n",
        "!pip install transformers\n",
        "\n",
        "# Import GPT-2 from HuggingFace\n",
        "from transformers import pipeline\n",
        "\n",
        "# Load the GPT-2 model\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "\n",
        "# Your own sentence prompt\n",
        "prompt = \"My name is Nilisha and I'm exploring the world of Generative AI.\"\n",
        "\n",
        "# Generate text using GPT-2\n",
        "result = generator(prompt, max_length=80, num_return_sequences=1)\n",
        "\n",
        "# Print the generated result\n",
        "print(result[0]['generated_text'])\n"
      ]
    }
  ]
}